{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark libraries\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, FloatType, ArrayType\n",
    "from pyspark.sql.functions import col, udf, when\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "# python libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_to_float(x):\n",
    "    x_replace_minus = x.replace(u'\\u2212', '-')\n",
    "    if x_replace_minus == '-':\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(x_replace_minus)\n",
    "\n",
    "udf_convert_string_to_float = udf(lambda x: convert_string_to_float(x), FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_get_percentage_game = udf(lambda x, y: x / y, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_create_features = udf(lambda s,t,u,v,w,x,y,z: Vectors.dense([s,t,u,v,w,x,y,z]), VectorUDT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_string(date, month, year):\n",
    "    return year + \"/\" + month + \"/\" + date\n",
    "\n",
    "udf_get_date_string = udf(lambda date, month, year: get_date_string(date, month, year), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win_team_1(score_team_1, score_team_2):\n",
    "    if score_team_1 > score_team_2:\n",
    "        return 2.0\n",
    "    elif score_team_1 < score_team_2:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "udf_win_team_1 = udf(lambda team_1, team_2: win_team_1(team_1, team_2), FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_diff_features = udf(lambda features_1, features_2: features_1 - features_2, VectorUDT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"rankGroup_local\", StringType(), True),\n",
    "    StructField(\"rankGroup_global\", StringType(), True),\n",
    "    StructField(\"teamGroup_team\", StringType(), True),\n",
    "    StructField(\"ratingGroup_rating\", StringType(), True),\n",
    "    StructField(\"highestGroup_rank_max\", StringType(), True),\n",
    "    StructField(\"highestGroup_rating_max\", StringType(), True),\n",
    "    StructField(\"averageGroup_rank_avg\", StringType(), True),\n",
    "    StructField(\"averageGroup_rating_avg\", StringType(), True),\n",
    "    StructField(\"lowestGroup_rank_min\", StringType(), True),\n",
    "    StructField(\"lowestGroup_rating_min\", StringType(), True),\n",
    "    StructField(\"change3mGroup_rank_three_month_change\", StringType(), True),\n",
    "    StructField(\"change3mGroup_rating_three_month_change\", StringType(), True),\n",
    "    StructField(\"change6mGroup_rank_six_month_change\", StringType(), True),\n",
    "    StructField(\"change6mGroup_rating_six_month_change\", StringType(), True),\n",
    "    StructField(\"change1yGroup_rank_one_year_change\", StringType(), True),\n",
    "    StructField(\"change1yGroup_rating_one_year_change\", StringType(), True),\n",
    "    StructField(\"change2yGroup_rank_two_year_change\", StringType(), True),\n",
    "    StructField(\"change2yGroup_rating_two_year_change\", StringType(), True),\n",
    "    StructField(\"change5yGroup_rank_five_year_change\", StringType(), True),\n",
    "    StructField(\"change5yGroup_rating_five_year_change\", StringType(), True),\n",
    "    StructField(\"change10yGroup_rank_ten_year_change\", StringType(), True),\n",
    "    StructField(\"change10yGroup_rating_ten_year_change\", StringType(), True),\n",
    "    StructField(\"matchesGroup_total\", StringType(), True),\n",
    "    StructField(\"matchesGroup_home\", StringType(), True),\n",
    "    StructField(\"matchesGroup_away\", StringType(), True),\n",
    "    StructField(\"matchesGroup_neutral\", StringType(), True),\n",
    "    StructField(\"matchesGroup_wins\", StringType(), True),\n",
    "    StructField(\"matchesGroup_losses\", StringType(), True),\n",
    "    StructField(\"matchesGroup_draws\", StringType(), True),\n",
    "    StructField(\"goalsGroup_for\", StringType(), True),\n",
    "    StructField(\"goalsGroup_against\", StringType(), True)\n",
    "])\n",
    "\n",
    "names_to_convert = schema.names\n",
    "names_to_convert.remove(\"teamGroup_team\")\n",
    "\n",
    "\n",
    "AFC_qualifying_start = spark.read.csv(\"../data/AFC/2014_World_Cup_AFC_qualifying_start.tsv\", sep=\"\\t\", \n",
    "                                      schema=schema, header=False)\\\n",
    "                                 .select([udf_convert_string_to_float(col(name)).alias(name) for name in names_to_convert] + [\"teamGroup_team\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+------------+---------------+------------+--------------+-------------+-----------+---------------+\n",
      "|team|matches_home|matches_away|matches_neutral|matches_wins|matches_losses|matches_draws|matches_for|matches_against|\n",
      "+----+------------+------------+---------------+------------+--------------+-------------+-----------+---------------+\n",
      "|  JP|  0.37785017|    0.252443|     0.36970684|  0.45114008|    0.32899022|    0.2198697|  1.6905538|       1.223127|\n",
      "|  KR|  0.31050768|  0.23966943|      0.4498229|   0.5478158|    0.20070839|    0.2514758|   1.853601|      0.9020071|\n",
      "|  AU|   0.4437086|   0.3620309|      0.1942605|   0.5121413|    0.27593818|   0.21192053|   2.039735|      1.1037527|\n",
      "|  IR|        0.34|       0.278|          0.382|       0.546|         0.218|        0.236|       1.87|          0.826|\n",
      "|  CN|  0.33032492|  0.33754513|     0.33212996|  0.51805055|    0.27436823|   0.20758122|  1.9801444|      1.0361011|\n",
      "+----+------------+------------+---------------+------------+--------------+-------------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AFC_qualifying_start = AFC_qualifying_start\\\n",
    ".withColumn(\"matches_home\",    udf_get_percentage_game(col(\"matchesGroup_home\"), col(\"matchesGroup_total\")))\\\n",
    ".withColumn(\"matches_away\",    udf_get_percentage_game(col(\"matchesGroup_away\"), col(\"matchesGroup_total\")))\\\n",
    ".withColumn(\"matches_neutral\", udf_get_percentage_game(col(\"matchesGroup_neutral\"), col(\"matchesGroup_total\")))\\\n",
    ".withColumn(\"matches_wins\",    udf_get_percentage_game(col(\"matchesGroup_wins\"), col(\"matchesGroup_total\")))\\\n",
    ".withColumn(\"matches_losses\",  udf_get_percentage_game(col(\"matchesGroup_losses\"), col(\"matchesGroup_total\")))\\\n",
    ".withColumn(\"matches_draws\",  udf_get_percentage_game(col(\"matchesGroup_draws\"), col(\"matchesGroup_total\")))\\\n",
    ".withColumn(\"matches_for\",    udf_get_percentage_game(col(\"goalsGroup_for\"), col(\"matchesGroup_total\")))\\\n",
    ".withColumn(\"matches_against\",  udf_get_percentage_game(col(\"goalsGroup_against\"), col(\"matchesGroup_total\")))\\\n",
    ".select(col(\"teamGroup_team\").alias(\"team\"), col(\"matches_home\"), col(\"matches_away\"), col(\"matches_neutral\"), \n",
    "        col(\"matches_wins\"), col(\"matches_losses\"), col(\"matches_draws\"),\n",
    "        col(\"matches_for\"), col(\"matches_against\"))\n",
    "\n",
    "AFC_qualifying_start.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|team|            features|\n",
      "+----+--------------------+\n",
      "|  JP|[0.37785017490386...|\n",
      "|  KR|[0.31050768494606...|\n",
      "|  AU|[0.44370859861373...|\n",
      "|  IR|[0.34000000357627...|\n",
      "|  CN|[0.33032491803169...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AFC_qualifying_start = AFC_qualifying_start\\\n",
    ".withColumn(\"features\", udf_create_features(col(\"matches_home\"), col(\"matches_away\"), col(\"matches_neutral\"),\n",
    "                                            col(\"matches_wins\"), col(\"matches_losses\"), col(\"matches_draws\"),\n",
    "                                            col(\"matches_for\"),  col(\"matches_against\")))\\\n",
    ".select(\"team\", \"features\")\n",
    "\n",
    "# AFC_qualifying_start.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([1.0, 2.0, 3.0, 5.0])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vectors.dense([1,2,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"year\", StringType(), True),\n",
    "    StructField(\"month\", StringType(), True),\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"team_1\", StringType(), True),\n",
    "    StructField(\"team_2\", StringType(), True),\n",
    "    StructField(\"score_team_1\", IntegerType(), True),\n",
    "    StructField(\"score_team_2\", IntegerType(), True),\n",
    "    StructField(\"tournament\", StringType(), True),\n",
    "    StructField(\"country_played\", StringType(), True),\n",
    "    StructField(\"rating_moved\", StringType(), True),\n",
    "    StructField(\"rating_team_1\", StringType(), True),\n",
    "    StructField(\"rating_team_2\", StringType(), True),\n",
    "    StructField(\"rank_moved_team_1\", StringType(), True),\n",
    "    StructField(\"rank_moved_team_2\", StringType(), True),\n",
    "    StructField(\"rank_team_1\", StringType(), True),\n",
    "    StructField(\"rank_team_2\", StringType(), True)\n",
    "])\n",
    "\n",
    "AFC_qualifying_results = spark.read.csv(\"../data/AFC/2014_World_Cup_AFC_qualifying_results.tsv\", sep=\"\\t\", \n",
    "                                        schema=schema, header=False)\\\n",
    "                              .withColumn(\"new_date\", udf_get_date_string(col(\"date\"), col(\"month\"), col(\"year\")))\\\n",
    "                              .drop(\"date\").drop(\"month\").drop(\"year\").withColumnRenamed(\"new_date\", \"date\")\n",
    "\n",
    "names_to_convert = AFC_qualifying_results.schema.names\n",
    "names_to_remove = [\"date\",  \"team_1\", \"team_2\", \"score_team_1\", \"score_team_2\", \"tournament\", \"country_played\"]\n",
    "for name in names_to_remove: names_to_convert.remove(name)\n",
    "\n",
    "\n",
    "AFC_qualifying_results = AFC_qualifying_results\\\n",
    "                         .select([udf_convert_string_to_float(col(name)).alias(name) for name in names_to_convert] + names_to_remove)\\\n",
    "                         .select(\"team_1\", \"team_2\", \"score_team_1\", \"score_team_2\")\\\n",
    "                         .withColumn(\"label\", udf_win_team_1(col(\"score_team_1\"), col(\"score_team_2\")))\\\n",
    "                         .select(\"team_1\", \"team_2\", \"label\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = AFC_qualifying_results.join(AFC_qualifying_start, AFC_qualifying_results.team_1 == AFC_qualifying_start.team)\\\n",
    ".withColumnRenamed(\"features\", \"features_1\").drop(\"team\")\\\n",
    ".join(AFC_qualifying_start, AFC_qualifying_results.team_2 == AFC_qualifying_start.team)\\\n",
    ".withColumnRenamed(\"features\", \"features_2\").drop(\"team\")\\\n",
    ".withColumn(\"features\", udf_diff_features(col(\"features_1\"), col(\"features_2\")))\\\n",
    ".select(\"label\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  2.0|[-0.0924882665276...|\n",
      "|  2.0|[0.02913619577884...|\n",
      "|  2.0|[0.08815789222717...|\n",
      "|  0.0|[-0.0671749860048...|\n",
      "|  2.0|[-0.1738087832927...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "DecisionTreeClassifier(self, featuresCol=\"features\", labelCol=\"label\", predictionCol=\"prediction\", probabilityCol=\"probability\", rawPredictionCol=\"rawPrediction\", maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0, maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10, impurity=\"gini\", seed=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", family=\"multinomial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define grid parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParamGridBuilder()\\\n",
    ".addGrid(logistic_regression.maxIter, [10, 15, 20])\\\n",
    ".addGrid(logistic_regression.regParam, [0.0, 0.1, 0.5, 1.0])\\\n",
    ".addGrid(logistic_regression.elasticNetParam, [0.0, 0.1, 0.5, 1.0])\\\n",
    ".build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple logistic regression application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 440\n",
      "Test count: 111\n",
      "Accuracy on the train dataset: 0.620454545455\n",
      "Accuracy on the test dataset: 0.594594594595\n"
     ]
    }
   ],
   "source": [
    "print(\"Train count: {0}\".format(train.count()))\n",
    "print(\"Test count: {0}\".format(test.count()))\n",
    "\n",
    "model = logistic_regression.setMaxIter(20).setRegParam(0.0).fit(train)\n",
    "train_prediction = model.transform(train)\n",
    "test_prediction = model.transform(test)\n",
    "\n",
    "print(\"Accuracy on the train dataset: {0}\".format(evaluator.evaluate(train_prediction)))\n",
    "print(\"Accuracy on the test dataset: {0}\".format(evaluator.evaluate(test_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined Cross Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=logistic_regression, estimatorParamMaps=grid, evaluator=evaluator, numFolds=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prediction = cv_model.transform(train)\n",
    "test_prediction = cv_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train dataset: 0.611479028698\n",
      "Accuracy on the test dataset: 0.540816326531\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on the train dataset: {0}\".format(evaluator.evaluate(train_prediction)))\n",
    "print(\"Accuracy on the test dataset: {0}\".format(evaluator.evaluate(test_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined Train Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TrainValidationSplit(estimator=logistic_regression, estimatorParamMaps=grid, evaluator=evaluator, trainRatio=0.75)\n",
    "tv_model = tv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prediction = tv_model.transform(train)\n",
    "test_prediction = tv_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train dataset: 0.62472406181\n",
      "Accuracy on the test dataset: 0.561224489796\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on the train dataset: {0}\".format(evaluator.evaluate(train_prediction)))\n",
    "print(\"Accuracy on the test dataset: {0}\".format(evaluator.evaluate(test_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
