{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType\n",
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+-------------------+------------+------------+\n",
      "|group|      team_1|             team_2|      team_3|      team_4|\n",
      "+-----+------------+-------------------+------------+------------+\n",
      "|    A|      Brazil|            Croatia|      Mexico|    Cameroon|\n",
      "|    B|       Spain|            Holland|       Chile|   Australia|\n",
      "|    C|    Colombia|             Greece| Ivory Coast|       Japan|\n",
      "|    D|     Uruguay|         Costa Rica|     England|       Italy|\n",
      "|    E| Switzerland|            Ecuador|      France|    Honduras|\n",
      "|    F|   Argentina| Bosnia-Herzegovina|        Iran|     Nigeria|\n",
      "|    G|     Germany|           Portugal|       Ghana|         USA|\n",
      "|    H|     Belgium|            Algeria|      Russia| South Korea|\n",
      "+-----+------------+-------------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"group\", StringType(), True),\n",
    "    StructField(\"team_1\", StringType(), True),\n",
    "    StructField(\"team_2\", StringType(), True),\n",
    "    StructField(\"team_3\", StringType(), True),\n",
    "    StructField(\"team_4\", StringType(), True),\n",
    "])\n",
    "\n",
    "data = spark.read.csv(\"../data/groups.csv\", sep=\",\", schema=schema, header=False)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_define_matches = udf(lambda x,y,z,t: list(combinations([x, y, z, t], 2)), ArrayType(ArrayType(StringType())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn(\"matches\", udf_define_matches(col(\"team_1\"), col(\"team_2\"), col(\"team_3\"), col(\"team_4\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_matches_group = udf(lambda group, matches: [[group] + match for match in matches], ArrayType(ArrayType(StringType())))\n",
    "\n",
    "\n",
    "all_matches = data\\\n",
    ".withColumn(\"group_matches\", udf_matches_group(col(\"group\"), col(\"matches\")))\\\n",
    ".select(\"group_matches\").rdd.map(lambda x: x[\"group_matches\"]).collect()\n",
    "\n",
    "matches_flattened_list = [y for x in all_matches for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+---------+\n",
      "|group|  team_1|   team_2|\n",
      "+-----+--------+---------+\n",
      "|    A|  Brazil|  Croatia|\n",
      "|    A|  Brazil|   Mexico|\n",
      "|    A|  Brazil| Cameroon|\n",
      "|    A| Croatia|   Mexico|\n",
      "|    A| Croatia| Cameroon|\n",
      "+-----+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = schema = StructType([\n",
    "    StructField(\"group\", StringType(), True), \n",
    "    StructField(\"team_1\", StringType(), True),\n",
    "    StructField(\"team_2\", StringType(), True),\n",
    "])\n",
    "\n",
    "matches = spark.createDataFrame(matches_flattened_list, schema=schema)\n",
    "\n",
    "matches.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matches.coalesce(1).write.csv(\"../data/first_round_matches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First round define all matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+--------+\n",
      "|group| team_1|  team_2|\n",
      "+-----+-------+--------+\n",
      "|    A| Brazil| Croatia|\n",
      "|    A| Brazil|  Mexico|\n",
      "|    A| Brazil|Cameroon|\n",
      "|    A|Croatia|  Mexico|\n",
      "|    A|Croatia|Cameroon|\n",
      "|    A| Mexico|Cameroon|\n",
      "+-----+-------+--------+\n",
      "\n",
      "+-----+------+--------+\n",
      "|group|team_1|  team_2|\n",
      "+-----+------+--------+\n",
      "|    A|Brazil| Croatia|\n",
      "|    A|Brazil|  Mexico|\n",
      "|    A|Brazil|Cameroon|\n",
      "+-----+------+--------+\n",
      "\n",
      "+-----+------+------+\n",
      "|group|team_1|team_2|\n",
      "+-----+------+------+\n",
      "+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"group\", StringType(), True),\n",
    "    StructField(\"team_1\", StringType(), True),\n",
    "    StructField(\"team_2\", StringType(), True)])\n",
    "all_matches = spark.read.csv(\"../data/first_round_matches/\", sep=\",\", header=False, schema=schema)\n",
    "all_matches.filter(col(\"group\") == \"A\").show()\n",
    "all_matches.filter(col(\"team_1\") == \"Brazil\").show()\n",
    "all_matches.filter(col(\"team_2\") == \"Brazil\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups: [u'F', u'E', u'B', u'D', u'C', u'A', u'G', u'H']\n"
     ]
    }
   ],
   "source": [
    "groups = all_matches.select(\"group\").distinct().rdd.map(lambda x: x[\"group\"]).collect()\n",
    "print(\"Groups: {0}\".format(groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_matches = {group:{} for group in groups}\n",
    "rdd_matches = all_matches.rdd.map(lambda x: (x[\"group\"], x[\"team_1\"], x[\"team_2\"])).collect()\n",
    "for group in dic_matches.keys():\n",
    "    group_matches = filter(lambda x: x[0] == group, rdd_matches)\n",
    "    for matches in group_matches:\n",
    "        team_1 = matches[1]\n",
    "        team_2 = matches[2]\n",
    "        dic_matches[group][team_1+'/'+team_2] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'Brazil/Cameroon': None,\n",
       " u'Brazil/Croatia': None,\n",
       " u'Brazil/Mexico': None,\n",
       " u'Croatia/Cameroon': None,\n",
       " u'Croatia/Mexico': None,\n",
       " u'Mexico/Cameroon': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_matches[\"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
