{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, IntegerType, FloatType\n",
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "from itertools import combinations\n",
    "import sys\n",
    "sys.path.append(\"../python/\")\n",
    "from featurization_data import FeaturizationData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|team|    country|\n",
      "+----+-----------+\n",
      "|  AN|       Aden|\n",
      "|  AF|Afghanistan|\n",
      "|  AL|    Albania|\n",
      "|  DZ|    Algeria|\n",
      "|  AD|    Andorra|\n",
      "+----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "            StructField(\"team\", StringType(), True),\n",
    "            StructField(\"country\", StringType(), True)])\n",
    "teams = spark.read.csv(\"../data/common/en.teams.tsv\", sep=\"\\t\", header=False, schema=schema)\n",
    "teams.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BooleanType' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ec6f7deac225>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mudf_filter_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilter_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooleanType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2014/06/12\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2014/06/26\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BooleanType' is not defined"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"year\", StringType(), True),\n",
    "    StructField(\"month\", StringType(), True),\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"team_1\", StringType(), True),\n",
    "    StructField(\"team_2\", StringType(), True),\n",
    "    StructField(\"score_team_1\", IntegerType(), True),\n",
    "    StructField(\"score_team_2\", IntegerType(), True),\n",
    "    StructField(\"tournament\", StringType(), True),\n",
    "    StructField(\"country_played\", StringType(), True),\n",
    "    StructField(\"rating_moved\", StringType(), True),\n",
    "    StructField(\"rating_team_1\", StringType(), True),\n",
    "    StructField(\"rating_team_2\", StringType(), True),\n",
    "    StructField(\"rank_moved_team_1\", StringType(), True),\n",
    "    StructField(\"rank_moved_team_2\", StringType(), True),\n",
    "    StructField(\"rank_team_1\", StringType(), True),\n",
    "    StructField(\"rank_team_2\", StringType(), True)\n",
    "])\n",
    "\n",
    "def get_date_string(date, month, year):\n",
    "    return str(year) + \"/\" + str(month) + \"/\" + str(date)\n",
    "\n",
    "udf_get_date = udf(lambda date, month, year: get_date_string(date, month, year), StringType())\n",
    "\n",
    "start_date, end_date = \"2014/06/12\", \"2014/06/26\"\n",
    "\n",
    "def filter_date(date, start_date, end_date):\n",
    "    if ((date >= start_date) and (date <= end_date)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "udf_filter_date = udf(lambda date: filter_date(date, start_date, end_date), BooleanType())\n",
    "\n",
    "start_date, end_date = \"2014/06/12\", \"2014/06/26\"\n",
    "\n",
    "data = (spark.read.csv(\"../data/WCF/2014_World_Cup_WCF_qualifying_results.tsv\", sep=\"\\t\", schema=schema)\\\n",
    ".withColum(\"new_date\", udf_get_date(col(\"date\"), col(\"month\"), col(\"year\")))\n",
    "            .select(\"team_1\", \"team_2\", \"score_team_1\", \"score_team_2\", \"new_date\")\n",
    "    .filter(udf_filter_date(col(\"new_date\"))))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------+------------+\n",
      "|team_1|team_2|score_team_1|score_team_2|\n",
      "+------+------+------------+------------+\n",
      "|    BR|    HR|           3|           1|\n",
      "|    CL|    AU|           3|           1|\n",
      "|    MX|    CM|           1|           0|\n",
      "|    NL|    ES|           5|           1|\n",
      "|    CO|    GR|           3|           0|\n",
      "|    CR|    UY|           3|           1|\n",
      "|    IT|    EN|           2|           1|\n",
      "|    CI|    JP|           2|           1|\n",
      "|    AR|    BA|           2|           1|\n",
      "|    FR|    HN|           3|           0|\n",
      "|    CH|    EC|           2|           1|\n",
      "|    DE|    PT|           4|           0|\n",
      "|    IR|    NG|           0|           0|\n",
      "|    US|    GH|           2|           1|\n",
      "|    BE|    DZ|           2|           1|\n",
      "|    BR|    MX|           0|           0|\n",
      "|    RU|    KR|           1|           1|\n",
      "|    CL|    ES|           2|           0|\n",
      "|    HR|    CM|           4|           0|\n",
      "|    NL|    AU|           3|           2|\n",
      "+------+------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_get_team_1 = udf(lambda x: x[0], StringType())\n",
    "udf_get_team_2 = udf(lambda x: x[1], StringType())\n",
    "\n",
    "def result_team_2(result):\n",
    "    if (result == 2):\n",
    "        return 1.0\n",
    "    elif (result == 1):\n",
    "        return 2.0\n",
    "    else:\n",
    "        return 0.0\n",
    "udf_result_team_2 = udf(lambda result: result_team_2(result), FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-----+--------+------+------+-------------+\n",
      "|label|result_team_1|group| matches|team_1|team_2|result_team_2|\n",
      "+-----+-------------+-----+--------+------+------+-------------+\n",
      "|  2.0|          2.0|    A|[BR, HR]|    BR|    HR|          1.0|\n",
      "|  0.0|          2.0|    A|[BR, MX]|    BR|    MX|          1.0|\n",
      "|  2.0|          2.0|    A|[BR, CM]|    BR|    CM|          1.0|\n",
      "|  2.0|          2.0|    A|[HR, CM]|    HR|    CM|          1.0|\n",
      "|  2.0|          2.0|    A|[MX, CM]|    MX|    CM|          1.0|\n",
      "+-----+-------------+-----+--------+------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = (data\n",
    ".withColumn(\"team_1\", udf_get_team_1(col(\"matches\")))\n",
    ".withColumn(\"team_2\", udf_get_team_2(col(\"matches\")))\n",
    ".withColumn(\"result_team_2\", udf_result_team_2(col(\"prediction\")))\n",
    ".withColumnRenamed(\"prediction\", \"result_team_1\") \n",
    "        \n",
    ")\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-----+--------+------+------+-------------+---------+---------+\n",
      "|label|result_team_1|group| matches|team_1|team_2|result_team_2|country_1|country_2|\n",
      "+-----+-------------+-----+--------+------+------+-------------+---------+---------+\n",
      "|  2.0|          2.0|    A|[BR, HR]|    BR|    HR|          1.0|   Brazil|  Croatia|\n",
      "|  0.0|          2.0|    A|[BR, MX]|    BR|    MX|          1.0|   Brazil|   Mexico|\n",
      "|  2.0|          2.0|    A|[BR, CM]|    BR|    CM|          1.0|   Brazil| Cameroon|\n",
      "|  2.0|          2.0|    A|[HR, CM]|    HR|    CM|          1.0|  Croatia| Cameroon|\n",
      "|  2.0|          2.0|    A|[MX, CM]|    MX|    CM|          1.0|   Mexico| Cameroon|\n",
      "+-----+-------------+-----+--------+------+------+-------------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = (data.join(teams, data.team_1 == teams.team)\n",
    ".withColumnRenamed(\"country\", \"country_1\").drop(\"team\")\n",
    ".join(teams, data.team_2 == teams.team)\n",
    ".withColumnRenamed(\"country\", \"country_2\").drop(\"team\"))\n",
    "\n",
    "data.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((u'Mexico', 2.0), 1), ((u'Croatia', 2.0), 1), ((u'Brazil', 2.0), 3)]\n",
      "[((u'Croatia', 1.0), 1), ((u'Cameroon', 1.0), 3), ((u'Mexico', 1.0), 1)]\n"
     ]
    }
   ],
   "source": [
    "rdd_team_1 = (data\n",
    "              .groupBy([\"country_1\", \"result_team_1\"]).count()\n",
    "              .rdd\n",
    "              .map(lambda x: ((x[\"country_1\"], x[\"result_team_1\"]), x[\"count\"])))\n",
    "\n",
    "rdd_team_2 = (data\n",
    "              .groupBy([\"country_2\", \"result_team_2\"]).count()\n",
    "              .rdd\n",
    "              .map(lambda x: ((x[\"country_2\"], x[\"result_team_2\"]), x[\"count\"])))\n",
    "\n",
    "print(rdd_team_1.collect())\n",
    "print(rdd_team_2.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_union = (rdd_team_1\n",
    "             .union(rdd_team_2)\n",
    "             .reduceByKey(lambda x,y: x + y)\n",
    "             .map(lambda x: (x[0][0], [(x[0][1], x[1])]))\n",
    "             .reduceByKey(lambda x,y: x + y)\n",
    "             .map(lambda x: (x[0], sorted(x[1], key=lambda tup: tup[0], reverse=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Brazil', [(2.0, 3)]),\n",
       " (u'Croatia', [(2.0, 1), (1.0, 1)]),\n",
       " (u'Cameroon', [(1.0, 3)]),\n",
       " (u'Mexico', [(2.0, 1), (1.0, 1)])]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_union.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+--------------------+------------+--------------+\n",
      "|group|   country_1|           country_2|   country_3|     country_4|\n",
      "+-----+------------+--------------------+------------+--------------+\n",
      "|    A|      Brazil|             Croatia|      Mexico|      Cameroon|\n",
      "|    B|       Spain|         Netherlands|       Chile|     Australia|\n",
      "|    C|    Colombia|              Greece| Ivory Coast|         Japan|\n",
      "|    D|     Uruguay|          Costa Rica|     England|         Italy|\n",
      "|    E| Switzerland|             Ecuador|      France|      Honduras|\n",
      "|    F|   Argentina| Bosnia and Herze...|        Iran|       Nigeria|\n",
      "|    G|     Germany|            Portugal|       Ghana| United States|\n",
      "|    H|     Belgium|             Algeria|      Russia|   South Korea|\n",
      "+-----+------------+--------------------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "            StructField(\"group\", StringType(), True),\n",
    "            StructField(\"country_1\", StringType(), True),\n",
    "            StructField(\"country_2\", StringType(), True),\n",
    "            StructField(\"country_3\", StringType(), True),\n",
    "            StructField(\"country_4\", StringType(), True)])\n",
    "\n",
    "groups = spark.read.csv(\"../data/groups.csv\", sep=\",\", schema=schema, header=False)\n",
    "\n",
    "groups.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+--------------------+------------+--------------+--------------------+\n",
      "|group|   country_1|           country_2|   country_3|     country_4|                test|\n",
      "+-----+------------+--------------------+------------+--------------+--------------------+\n",
      "|    A|      Brazil|             Croatia|      Mexico|      Cameroon|[ Brazil,  Croati...|\n",
      "|    B|       Spain|         Netherlands|       Chile|     Australia|[ Spain,  Netherl...|\n",
      "|    C|    Colombia|              Greece| Ivory Coast|         Japan|[ Colombia,  Gree...|\n",
      "|    D|     Uruguay|          Costa Rica|     England|         Italy|[ Uruguay,  Costa...|\n",
      "|    E| Switzerland|             Ecuador|      France|      Honduras|[ Switzerland,  E...|\n",
      "|    F|   Argentina| Bosnia and Herze...|        Iran|       Nigeria|[ Argentina,  Bos...|\n",
      "|    G|     Germany|            Portugal|       Ghana| United States|[ Germany,  Portu...|\n",
      "|    H|     Belgium|             Algeria|      Russia|   South Korea|[ Belgium,  Alger...|\n",
      "+-----+------------+--------------------+------------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "udf_list_country = udf(lambda country_1,country_2,country_3,country_4: [country_1, country_2, country_3, country_4], ArrayType(StringType()))\n",
    "groups.withColumn(\"test\", udf_list_country(col(\"country_1\"),col(\"country_2\"),col(\"country_3\"),col(\"country_4\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, MultilayerPerceptronClassifier, OneVsRest, LinearSVC, GBTClassifier\n",
    "from pyspark.ml.classification import LogisticRegressionModel, DecisionTreeClassificationModel, RandomForestClassificationModel,  MultilayerPerceptronClassificationModel, OneVsRestModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MultilayerPerceptronClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "\n",
    "grid = ParamGridBuilder()\\\n",
    "        .addGrid(estimator.layers, [[2, 2, 2]])\\\n",
    "        .build() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation = TrainValidationSplit(estimator=estimator, \n",
    "                                        estimatorParamMaps=grid, \n",
    "                                        evaluator=evaluator, \n",
    "                                        trainRatio=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "     (0.0, Vectors.dense([0.0, 0.0])),\n",
    "     (1.0, Vectors.dense([0.0, 1.0])),\n",
    "     (1.0, Vectors.dense([1.0, 0.0])),\n",
    "     (0.0, Vectors.dense([1.0, 1.0]))], [\"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{Param(parent=u'MultilayerPerceptronClassifier_4db6a73068a1467633e7', name='layers', doc='Sizes of layers from input layer to output layer E.g., Array(780, 100, 10) means 780 inputs, one hidden layer with 100 neurons and output layer of 10 neurons.'): [2,\n",
       "   2,\n",
       "   2]}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_validation.getEstimatorParamMaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
